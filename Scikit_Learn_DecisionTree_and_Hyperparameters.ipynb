{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkeldenich/Scikit_Learn_DecisionTree_and_Hyperparameters/blob/main/Scikit_Learn_DecisionTree_and_Hyperparameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree How to Use It and Its Hyperparameters**"
      ],
      "metadata": {
        "id": "uxAnEVyFxziT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [English Article](https://inside-machinelearning.com/en/decision-tree-and-hyperparameters/)\n",
        "- [French Article](https://inside-machinelearning.com/decision-tree/)"
      ],
      "metadata": {
        "id": "GSj13Z77x43X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see in details how Decision Tree works with [Scikit-Learn](https://scikit-learn.org/stable/) and especially how to use its hyperparameters to improve it!\n",
        "\n",
        "Decision Tree, is a Machine Learning algorithm used to classify data based on a set of conditions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fCAl_sNuyFyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<img src=\"https://inside-machinelearning.com/wp-content/uploads/2022/09/DecisionTree.jpg\" width=\"450\" text-align=\"center\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "wwjZVCWVy6xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this article we will see how Decision Tree works.**\n",
        "\n",
        "It is a powerful model that allowed us, [in our previous article to learn Machine Learning](https://inside-machinelearning.com/en/scikit-learn-project-start-ml/), to reach an accuracy of 60%. Thus the Decision Tree is the model that gave us the highest success rate.\n",
        "\n",
        "After having understood what a Decision Tree is, we’ll analyze the different hyperparameters that it provides.\n",
        "\n",
        "Will we be able to improve our Decision Tree by tweaking the hyperparameters? Let’s see that in this article!"
      ],
      "metadata": {
        "id": "wlmcwQ-wyJVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load data**"
      ],
      "metadata": {
        "id": "7-zkVnjFzV5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we’ll use the same data as [in our article on Machine Learning.](https://inside-machinelearning.com/en/scikit-learn-project-start-ml/) If you haven’t read it yet and you have the basics of Machine Learning, you’ll still be able to understand this tutorial.\n",
        "\n",
        "First of all, we import our datasets:"
      ],
      "metadata": {
        "id": "i-NKCHu7zX0I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrenwx9quuDr",
        "outputId": "37523141-c1a0-4539-92fe-1aab78b4f894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tkeldenich/datasets.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we are interested in is the [winequality-white.csv.](https://github.com/tkeldenich/First_Project_with_Scikit-Learn_MachineLearning/blob/main/winequality-white.csv)\n",
        "\n",
        "We use the Pandas library to open and display it:"
      ],
      "metadata": {
        "id": "4VaP7KZmzdNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/datasets/winequality-white.csv\", sep=\";\")\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "u7HSS0a_u6di",
        "outputId": "8cbec1d2-5b8f-4a84-ff1d-6be65161b4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.0              0.27         0.36            20.7      0.045   \n",
              "1            6.3              0.30         0.34             1.6      0.049   \n",
              "2            8.1              0.28         0.40             6.9      0.050   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
              "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
              "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      8.8        6  \n",
              "1      9.5        6  \n",
              "2     10.1        6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6c1cf7a-15ad-44e3-8cb6-9908c5163c98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0010</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9951</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6c1cf7a-15ad-44e3-8cb6-9908c5163c98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6c1cf7a-15ad-44e3-8cb6-9908c5163c98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6c1cf7a-15ad-44e3-8cb6-9908c5163c98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 7 features for 1 label.\n",
        "\n",
        "The objective is to predict the quality of the wines according to the features.\n",
        "\n",
        "We can directly create `X_train`, `X_test`, `y_train`, `y_test` for training the model."
      ],
      "metadata": {
        "id": "hVg2MK35z7KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = df.drop(['quality'], axis=1)\n",
        "labels = df[['quality']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)"
      ],
      "metadata": {
        "id": "afLqxMKKuvxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the dataset is loaded, let’s move on to what really interests us: the Decision Tree."
      ],
      "metadata": {
        "id": "fQDAtp280FQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Understand Decision Tree**"
      ],
      "metadata": {
        "id": "wL87Bh1U0bW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **In theory**"
      ],
      "metadata": {
        "id": "QRAt6hSb0dee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree is used in classification tasks.\n",
        "\n",
        "In our case, we use it to classify wines among 7 quality levels: [3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "The Decision Tree algorithm analyzes our data. It relies on the features (`fixed acidity`, `volatile acidity`, `citric acid`, `residual sugar`, `chlorides`, `free sulfur dioxide`, `total sulfur dioxide`, `density`, `pH`, `sulphates`, `alcohol`, `quality`) to predict to which class each wine belongs.\n",
        "\n",
        "**It starts with the feature that its algorithm finds most relevant, and creates two subgroups.**\n",
        "\n",
        "For example, if it analyzes that the wines of quality 3 have alcohol lower than 7%, it can create two subgroups: the group of wines lower than 7% (and of quality 3) and the groups of wines higher than 7% (and of quality 4, 5, 6, 7, 8, 9).\n",
        "\n",
        "> Thus, the alcohol level below 7% is a decision rule to discriminate and classify our data.\n",
        "\n",
        "The Decision Tree continues this process obtaining groups that correspond as well as possible to each of our classes and thereby classify the whole dataset.\n",
        "\n",
        "**However, in practice, a rule does not necessarily allow a perfect discrimination of our data.**\n",
        "\n",
        "Indeed, it is possible that in the wines with alcohol lower than 7%, there are not only wines of quality 3, but also others of quality 4, 5.\n",
        "\n",
        "It’ll then be necessary to continue the creation of discrimination rules on this group of data.\n",
        "\n",
        "This is how a Decision Tree can quickly end up with a large number of rules. Especially if our features are complex and poorly correlated with our labels, as shown by [our analysis of the correlation](https://inside-machinelearning.com/en/scikit-learn-project-start-ml/) rate between our features and our labels."
      ],
      "metadata": {
        "id": "9pXm3OWJ0dje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **In practice**"
      ],
      "metadata": {
        "id": "4giv3cyq04D9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The Decision Tree is composed of nodes, branches and leaves.\n",
        "\n",
        "**In a node, the algorithm tests a feature of our dataset to discriminate the data. This is where it creates a discrimination rule.**\n",
        "\n",
        "The test performed has 2 possible results: True or False.\n",
        "\n",
        "For example, in our case, a test can be: is alcohol rate higher than 7%?\n",
        "\n",
        "In both cases, the decision tree will create two paths: True and False.\n",
        "\n",
        "**These two options create two branches that lead to another node where another test will be performed to discriminate our data.**\n",
        "\n",
        "The first node is called the root.\n",
        "\n",
        "The final node of a branch is called a leaf. It signifies the decision making.\n",
        "\n",
        "The depth of a tree is defined by the length of the longest path between a root and a leaf.\n",
        "\n",
        "The following tree has 3 nodes, 2 leaves, 1 root and a depth of 1 :"
      ],
      "metadata": {
        "id": "MbTMnJpD04F3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<img src=\"https://inside-machinelearning.com/wp-content/uploads/2022/09/wine3.jpg\" width=\"600\" text-align=\"center\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "uCiWEP821BGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have several information in this tree. Let’s see that in detail:"
      ],
      "metadata": {
        "id": "pf80pK1Y1BI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **First attribute**"
      ],
      "metadata": {
        "id": "i6cDiYEV1Nar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first attribute indicates the feature (and its value) on which the algorithm relied to discriminate our data.\n",
        "\n",
        "*Note: the first attribute is not present in the leaf nodes.*"
      ],
      "metadata": {
        "id": "Lr5_l1701NdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Criterion (entropy or gini)**"
      ],
      "metadata": {
        "id": "wrf7jyK91Nfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entropy *(or gini according to the user’s choice, see below)* is the measure that allows to quantify the uncertainty on the discrimination rule used.\n",
        "\n",
        "The higher the entropy, the greater the uncertainty. Above 1, the uncertainty is considered high.\n",
        "\n",
        "With an uncertainty higher than 1, we have little chance to predict the classes on the created subgroups. However, this does not mean that the discrimination rule is incorrect.\n",
        "\n",
        "Indeed, Decision Tree calculates the discrimination that will allow to make the best prediction.\n",
        "\n",
        "It rather indicates that the created subgroups will need, as well, an analysis to determine a discrimination rule and create other subgroups."
      ],
      "metadata": {
        "id": "kxZZtldg1Nhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Samples**"
      ],
      "metadata": {
        "id": "ncspuL_11NkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Samples represents the number of data belonging to the subgroup of the node."
      ],
      "metadata": {
        "id": "XTn5LHEe1Nm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Value**"
      ],
      "metadata": {
        "id": "PU_KeQKO1wOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Value represents the number of data for each label in the node’s subgroup.\n",
        "\n",
        "For example, for the bottom left node with `value = [10, 103, 1021, 1102, 216, 30, 1]`, we have 10 wines of quality 3, 103 wines of quality 4, 1021 of quality 5, etc."
      ],
      "metadata": {
        "id": "xRFDe-VV1wQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Class**"
      ],
      "metadata": {
        "id": "Er1JQCbA1wS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class represents the decision taken if the current node would be a leaf.\n",
        "\n",
        "The Decision Tree takes the decision that will give it the highest accuracy.\n",
        "\n",
        "**For the root node, 1792 wines belong to class 6. All other classes have a lower number of wines. The optimal decision is therefore to predict class 6.**\n",
        "\n",
        "*Besides, if there is an equal number of data for each class in a node, the Decision Tree is programmed to choose the first class of the list of equal numbers.*\n",
        "\n",
        "We can notice that the two leaves give us the same class: 6 (which explains the entropy value). Indeed, our data being complex, we will need a Decision Tree with a higher depth to discriminate all our classes."
      ],
      "metadata": {
        "id": "SQ8CeCfJ1wVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decision Tree – the hyperparameters**"
      ],
      "metadata": {
        "id": "OTOAI3oS1wXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decision Tree has several hyperparameters. The most basic ones are :\n",
        "\n",
        "- **criterion *(“gini” or “entropy”)*** – the function (“gini” or “entropy”) used to calculate the uncertainty on the discrimination rule selected.\n",
        "- **splitter *(“best” or “random”)*** – the strategy used to choose the feature on which to create a discrimination rule. The default value is “best”. That is, for each node, the algorithm takes into account all features and chooses the one with the best criterion. If “random”, a random feature will be taken. The “random” technique is used to avoid overfitting.\n",
        "- **max_features *(integer)*** – The number of features to take into account when searching for the best split (best discrimination rule).\n",
        "- **random_state *(integer)*** – controls the randomness in the algorithm. If no number is specified, the algorithm will give it a random number for each new training. This will change the result for each new training. If a number is specified, the algorithm will always have the same result even after a new training."
      ],
      "metadata": {
        "id": "ZdWk_eO92DVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Size attributes**"
      ],
      "metadata": {
        "id": "9IkP4T69BEss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can list the parameters acting on the size of the Decision Tree\n",
        "\n",
        "- **max_depth *(integer)*** – the maximum tree depth.\n",
        "min_samples_split (integer) – The minimum number of samples required to create a decision rule.\n",
        "- **min_samples_leaf *(integer)*** – The minimum number of samples required to be in a leaf. A leaf will not be allowed to have a number of samples lower than this value. Ideal to overcome overfitting.\n",
        "- **max_leaf_nodes *(integer)*** – The maximum number of leaves contained in the Decision Tree.\n",
        "- **min_impurity_decrease *(integer)*** – The minimum impurity decrease value required to create a new decision rule. A node will be split if the split results in an impurity decrease greater than or equal to this value. The impurity is directly correlated to the **criterion** (thus, the more the entropy decreases too, the more the impurity decreases).\n",
        "\n",
        "We can initialize our tree with two hyperparameters:\n",
        "\n",
        "- **criterion** = ” entropy”\n",
        "- **max_depth** = 3"
      ],
      "metadata": {
        "id": "2i_mVq4V2QVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "decisionTree = tree.DecisionTreeClassifier(criterion=\"entropy\",\n",
        "                                           max_depth=3)"
      ],
      "metadata": {
        "id": "nNxW_hriu0lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the tree:"
      ],
      "metadata": {
        "id": "e9R3jRb92qgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decisionTree.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuxAnO2Qu1v5",
        "outputId": "1001c5ba-2a48-429d-f117-a5662d46d546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=3)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And compute its performance :"
      ],
      "metadata": {
        "id": "7cKbDTsz2taE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decisionTree.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2AcelHdu3UM",
        "outputId": "d772c859-576f-4bb9-aa9f-cd3b53323b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5040816326530613"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "50% accuracy, we’re far from the performance reached in [our article.](https://inside-machinelearning.com/en/scikit-learn-project-start-ml/)\n",
        "\n",
        "Let’s display the Tree to analyze the result:"
      ],
      "metadata": {
        "id": "mU-eRyQZ2ujd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_unique = labels.quality.unique().tolist()\n",
        "labels_unique.sort()\n",
        "labels_unique"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEM0oNR6_upx",
        "outputId": "56e02413-71ac-4141-9cae-92bb3098f2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "\n",
        "dot_data = tree.export_graphviz(decisionTree, out_file=None,\n",
        "                                feature_names=features.columns.to_list(),\n",
        "                                class_names=[str(x) for x in labels_unique],\n",
        "                                filled=True, rounded=True,\n",
        "                                special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"wine\")\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "3sBP3IBOvfgz",
        "outputId": "c0da1f0e-fe8f-4c0c-9867-612158f9f43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fe68d6faa90>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1871pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 1870.50 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-429 1866.5,-429 1866.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#d3f9f9\" stroke=\"#000000\" d=\"M1055.5,-425C1055.5,-425 794.5,-425 794.5,-425 788.5,-425 782.5,-419 782.5,-413 782.5,-413 782.5,-354 782.5,-354 782.5,-348 788.5,-342 794.5,-342 794.5,-342 1055.5,-342 1055.5,-342 1061.5,-342 1067.5,-348 1067.5,-354 1067.5,-354 1067.5,-413 1067.5,-413 1067.5,-419 1061.5,-425 1055.5,-425\"/>\n<text text-anchor=\"start\" x=\"875.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">alcohol ≤ 10.85</text>\n<text text-anchor=\"start\" x=\"874\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.851</text>\n<text text-anchor=\"start\" x=\"873\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3918</text>\n<text text-anchor=\"start\" x=\"790.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [15, 120, 1156, 1768, 714, 142, 3]</text>\n<text text-anchor=\"start\" x=\"896\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#f5fefe\" stroke=\"#000000\" d=\"M821,-306C821,-306 585,-306 585,-306 579,-306 573,-300 573,-294 573,-294 573,-235 573,-235 573,-229 579,-223 585,-223 585,-223 821,-223 821,-223 827,-223 833,-229 833,-235 833,-235 833,-294 833,-294 833,-300 827,-306 821,-306\"/>\n<text text-anchor=\"start\" x=\"632\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">volatile acidity ≤ 0.267</text>\n<text text-anchor=\"start\" x=\"652\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.635</text>\n<text text-anchor=\"start\" x=\"651\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2459</text>\n<text text-anchor=\"start\" x=\"581\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [8, 89, 1021, 1090, 223, 28, 0]</text>\n<text text-anchor=\"start\" x=\"674\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M847.3552,-341.8796C828.6814,-331.8697 808.6191,-321.1156 789.5672,-310.9031\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"791.0682,-307.7366 780.601,-306.0969 787.7611,-313.9062 791.0682,-307.7366\"/>\n<text text-anchor=\"middle\" x=\"787.8297\" y=\"-326.329\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#d9faf9\" stroke=\"#000000\" d=\"M1274,-306C1274,-306 1046,-306 1046,-306 1040,-306 1034,-300 1034,-294 1034,-294 1034,-235 1034,-235 1034,-229 1040,-223 1046,-223 1046,-223 1274,-223 1274,-223 1280,-223 1286,-229 1286,-235 1286,-235 1286,-294 1286,-294 1286,-300 1280,-306 1274,-306\"/>\n<text text-anchor=\"start\" x=\"1081\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">free sulfur dioxide ≤ 11.5</text>\n<text text-anchor=\"start\" x=\"1109\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.821</text>\n<text text-anchor=\"start\" x=\"1108\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1459</text>\n<text text-anchor=\"start\" x=\"1042\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 31, 135, 678, 491, 114, 3]</text>\n<text text-anchor=\"start\" x=\"1131\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1007.1916,-341.8796C1027.1378,-331.7791 1048.5805,-320.9209 1068.9108,-310.626\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1070.5146,-313.7371 1077.8548,-306.0969 1067.3522,-307.4921 1070.5146,-313.7371\"/>\n<text text-anchor=\"middle\" x=\"1070.07\" y=\"-326.154\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#bdf6f5\" stroke=\"#000000\" d=\"M474,-187C474,-187 254,-187 254,-187 248,-187 242,-181 242,-175 242,-175 242,-116 242,-116 242,-110 248,-104 254,-104 254,-104 474,-104 474,-104 480,-104 486,-110 486,-116 486,-116 486,-175 486,-175 486,-181 480,-187 474,-187\"/>\n<text text-anchor=\"start\" x=\"293\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">volatile acidity ≤ 0.207</text>\n<text text-anchor=\"start\" x=\"313\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.603</text>\n<text text-anchor=\"start\" x=\"312\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1312</text>\n<text text-anchor=\"start\" x=\"250\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 13, 386, 697, 188, 24, 0]</text>\n<text text-anchor=\"start\" x=\"335\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M584.4343,-222.8796C554.6285,-212.4168 522.5064,-201.1409 492.2511,-190.5203\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"493.0936,-187.1067 482.4988,-187.0969 490.7751,-193.7116 493.0936,-187.1067\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#bff7c6\" stroke=\"#000000\" d=\"M804.5,-187C804.5,-187 601.5,-187 601.5,-187 595.5,-187 589.5,-181 589.5,-175 589.5,-175 589.5,-116 589.5,-116 589.5,-110 595.5,-104 601.5,-104 601.5,-104 804.5,-104 804.5,-104 810.5,-104 816.5,-110 816.5,-116 816.5,-116 816.5,-175 816.5,-175 816.5,-181 810.5,-187 804.5,-187\"/>\n<text text-anchor=\"start\" x=\"653.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">alcohol ≤ 10.25</text>\n<text text-anchor=\"start\" x=\"652\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.472</text>\n<text text-anchor=\"start\" x=\"651\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1147</text>\n<text text-anchor=\"start\" x=\"597.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 76, 635, 393, 35, 4, 0]</text>\n<text text-anchor=\"start\" x=\"674\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M703,-222.8796C703,-214.6838 703,-205.9891 703,-197.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"706.5001,-197.298 703,-187.2981 699.5001,-197.2981 706.5001,-197.298\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#a7f3f2\" stroke=\"#000000\" d=\"M224,-68C224,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 224,0 224,0 230,0 236,-6 236,-12 236,-12 236,-56 236,-56 236,-62 230,-68 224,-68\"/>\n<text text-anchor=\"start\" x=\"67\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.623</text>\n<text text-anchor=\"start\" x=\"70\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 593</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 4, 120, 331, 118, 19, 0]</text>\n<text text-anchor=\"start\" x=\"89\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M272.3987,-103.9815C249.4668,-93.5876 224.9744,-82.4864 202.4101,-72.259\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"203.7554,-69.0261 193.2024,-68.0856 200.8656,-75.4018 203.7554,-69.0261\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#d3f9f9\" stroke=\"#000000\" d=\"M461.5,-68C461.5,-68 266.5,-68 266.5,-68 260.5,-68 254.5,-62 254.5,-56 254.5,-56 254.5,-12 254.5,-12 254.5,-6 260.5,0 266.5,0 266.5,0 461.5,0 461.5,0 467.5,0 473.5,-6 473.5,-12 473.5,-12 473.5,-56 473.5,-56 473.5,-62 467.5,-68 461.5,-68\"/>\n<text text-anchor=\"start\" x=\"313\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.516</text>\n<text text-anchor=\"start\" x=\"316\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 719</text>\n<text text-anchor=\"start\" x=\"262.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 9, 266, 366, 70, 5, 0]</text>\n<text text-anchor=\"start\" x=\"335\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M364,-103.9815C364,-95.618 364,-86.7965 364,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.5001,-78.2636 364,-68.2637 360.5001,-78.2637 367.5001,-78.2636\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#adf4b6\" stroke=\"#000000\" d=\"M706.5,-68C706.5,-68 503.5,-68 503.5,-68 497.5,-68 491.5,-62 491.5,-56 491.5,-56 491.5,-12 491.5,-12 491.5,-6 497.5,0 503.5,0 503.5,0 706.5,0 706.5,0 712.5,0 718.5,-6 718.5,-12 718.5,-12 718.5,-56 718.5,-56 718.5,-62 712.5,-68 706.5,-68\"/>\n<text text-anchor=\"start\" x=\"554\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.343</text>\n<text text-anchor=\"start\" x=\"557\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 923</text>\n<text text-anchor=\"start\" x=\"499.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 60, 553, 293, 14, 0, 0]</text>\n<text text-anchor=\"start\" x=\"576\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M666.5084,-103.9815C658.4305,-94.7908 649.8666,-85.0472 641.7774,-75.8436\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"644.3458,-73.4642 635.1152,-68.2637 639.088,-78.0855 644.3458,-73.4642\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#e6fcfb\" stroke=\"#000000\" d=\"M943.5,-68C943.5,-68 748.5,-68 748.5,-68 742.5,-68 736.5,-62 736.5,-56 736.5,-56 736.5,-12 736.5,-12 736.5,-6 742.5,0 748.5,0 748.5,0 943.5,0 943.5,0 949.5,0 955.5,-6 955.5,-12 955.5,-12 955.5,-56 955.5,-56 955.5,-62 949.5,-68 943.5,-68\"/>\n<text text-anchor=\"start\" x=\"795\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.781</text>\n<text text-anchor=\"start\" x=\"798\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 224</text>\n<text text-anchor=\"start\" x=\"744.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 16, 82, 100, 21, 4, 0]</text>\n<text text-anchor=\"start\" x=\"817\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M756.2479,-103.9815C768.6244,-94.3313 781.7828,-84.0714 794.1003,-74.4673\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"796.3225,-77.1728 802.0565,-68.2637 792.0182,-71.6525 796.3225,-77.1728\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#defbfa\" stroke=\"#000000\" d=\"M1249.5,-187C1249.5,-187 1070.5,-187 1070.5,-187 1064.5,-187 1058.5,-181 1058.5,-175 1058.5,-175 1058.5,-116 1058.5,-116 1058.5,-110 1064.5,-104 1070.5,-104 1070.5,-104 1249.5,-104 1249.5,-104 1255.5,-104 1261.5,-110 1261.5,-116 1261.5,-116 1261.5,-175 1261.5,-175 1261.5,-181 1255.5,-187 1249.5,-187\"/>\n<text text-anchor=\"start\" x=\"1108\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">citric acid ≤ 0.25</text>\n<text text-anchor=\"start\" x=\"1109\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.973</text>\n<text text-anchor=\"start\" x=\"1116\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 91</text>\n<text text-anchor=\"start\" x=\"1066.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 20, 25, 36, 8, 1, 0]</text>\n<text text-anchor=\"start\" x=\"1131\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1160,-222.8796C1160,-214.6838 1160,-205.9891 1160,-197.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1163.5001,-197.298 1160,-187.2981 1156.5001,-197.2981 1163.5001,-197.298\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#dbfafa\" stroke=\"#000000\" d=\"M1618,-187C1618,-187 1390,-187 1390,-187 1384,-187 1378,-181 1378,-175 1378,-175 1378,-116 1378,-116 1378,-110 1384,-104 1390,-104 1390,-104 1618,-104 1618,-104 1624,-104 1630,-110 1630,-116 1630,-116 1630,-175 1630,-175 1630,-181 1624,-187 1618,-187\"/>\n<text text-anchor=\"start\" x=\"1450.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">alcohol ≤ 12.083</text>\n<text text-anchor=\"start\" x=\"1453\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.742</text>\n<text text-anchor=\"start\" x=\"1452\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1368</text>\n<text text-anchor=\"start\" x=\"1386\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 11, 110, 642, 483, 113, 3]</text>\n<text text-anchor=\"start\" x=\"1475\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1280.3145,-222.8796C1310.6908,-212.3715 1343.438,-201.0432 1374.2559,-190.3824\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1375.4472,-193.6739 1383.7534,-187.0969 1373.1587,-187.0585 1375.4472,-193.6739\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#dbf29c\" stroke=\"#000000\" d=\"M1140,-68C1140,-68 986,-68 986,-68 980,-68 974,-62 974,-56 974,-56 974,-12 974,-12 974,-6 980,0 986,0 986,0 1140,0 1140,0 1146,0 1152,-6 1152,-12 1152,-12 1152,-56 1152,-56 1152,-62 1146,-68 1140,-68\"/>\n<text text-anchor=\"start\" x=\"1012\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.371</text>\n<text text-anchor=\"start\" x=\"1019\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15</text>\n<text text-anchor=\"start\" x=\"982\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 9, 3, 0, 3, 0, 0]</text>\n<text text-anchor=\"start\" x=\"1034\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 4</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1123.8808,-103.9815C1115.8853,-94.7908 1107.4087,-85.0472 1099.4021,-75.8436\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1102.012,-73.5111 1092.8079,-68.2637 1096.7307,-78.1055 1102.012,-73.5111\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#ccf8f7\" stroke=\"#000000\" d=\"M1360.5,-68C1360.5,-68 1181.5,-68 1181.5,-68 1175.5,-68 1169.5,-62 1169.5,-56 1169.5,-56 1169.5,-12 1169.5,-12 1169.5,-6 1175.5,0 1181.5,0 1181.5,0 1360.5,0 1360.5,0 1366.5,0 1372.5,-6 1372.5,-12 1372.5,-12 1372.5,-56 1372.5,-56 1372.5,-62 1366.5,-68 1360.5,-68\"/>\n<text text-anchor=\"start\" x=\"1220\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.855</text>\n<text text-anchor=\"start\" x=\"1227\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 76</text>\n<text text-anchor=\"start\" x=\"1177.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 11, 22, 36, 5, 1, 0]</text>\n<text text-anchor=\"start\" x=\"1242\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1201.3323,-103.9815C1210.5733,-94.6989 1220.3758,-84.8522 1229.6187,-75.5677\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1232.3152,-77.82 1236.89,-68.2637 1227.3543,-72.8813 1232.3152,-77.82\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#c5f7f7\" stroke=\"#000000\" d=\"M1605.5,-68C1605.5,-68 1402.5,-68 1402.5,-68 1396.5,-68 1390.5,-62 1390.5,-56 1390.5,-56 1390.5,-12 1390.5,-12 1390.5,-6 1396.5,0 1402.5,0 1402.5,0 1605.5,0 1605.5,0 1611.5,0 1617.5,-6 1617.5,-12 1617.5,-12 1617.5,-56 1617.5,-56 1617.5,-62 1611.5,-68 1605.5,-68\"/>\n<text text-anchor=\"start\" x=\"1453\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.722</text>\n<text text-anchor=\"start\" x=\"1456\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 827</text>\n<text text-anchor=\"start\" x=\"1398.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 9, 97, 420, 252, 44, 0]</text>\n<text text-anchor=\"start\" x=\"1475\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1504,-103.9815C1504,-95.618 1504,-86.7965 1504,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1507.5001,-78.2636 1504,-68.2637 1500.5001,-78.2637 1507.5001,-78.2636\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#f9fafe\" stroke=\"#000000\" d=\"M1850.5,-68C1850.5,-68 1647.5,-68 1647.5,-68 1641.5,-68 1635.5,-62 1635.5,-56 1635.5,-56 1635.5,-12 1635.5,-12 1635.5,-6 1641.5,0 1647.5,0 1647.5,0 1850.5,0 1850.5,0 1856.5,0 1862.5,-6 1862.5,-12 1862.5,-12 1862.5,-56 1862.5,-56 1862.5,-62 1856.5,-68 1850.5,-68\"/>\n<text text-anchor=\"start\" x=\"1698\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.648</text>\n<text text-anchor=\"start\" x=\"1701\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 541</text>\n<text text-anchor=\"start\" x=\"1643.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 2, 13, 222, 231, 69, 3]</text>\n<text text-anchor=\"start\" x=\"1720\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 7</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1595.229,-103.9815C1618.0676,-93.5876 1642.4604,-82.4864 1664.9331,-72.259\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1666.4514,-75.4135 1674.1033,-68.0856 1663.5518,-69.0423 1666.4514,-75.4135\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see here that the Decision Tree does not have enough leaves to predict classes 3, 8 and 9.\n",
        "\n",
        "Indeed the Decision Tree gives priority to the classes with the highest number of wines. Here, the tree has not yet had time to analyze the classes containing the least number of wines.\n",
        "\n",
        "\n",
        "We’ll need a higher depth to get a good Decision Tree."
      ],
      "metadata": {
        "id": "hfE2l60E22P0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pruned Decision Tree**"
      ],
      "metadata": {
        "id": "gjxT5jN1GRX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Pruning is a technique used to reduce the complexity of a Decision Tree.\n",
        "\n",
        "The idea is to measure the relevance of each node, and then to remove (to prune) the less critical ones, which add unnecessary complexity.\n",
        "\n",
        "Pruning is performed by the Decision Tree when we indicate a value to this hyperparameter :\n",
        "\n",
        "**ccp_alpha (float)** – The node (or nodes) with the highest complexity and less than **ccp_alpha** will be pruned.\n",
        "\n",
        "Let’s see that in practice:"
      ],
      "metadata": {
        "id": "j8Lr0EWh26V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "decisionTree = tree.DecisionTreeClassifier(criterion=\"entropy\",\n",
        "                                           ccp_alpha=0.015,\n",
        "                                           max_depth=3  \n",
        "                                           )"
      ],
      "metadata": {
        "id": "zivvpLgSGRX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the tree:"
      ],
      "metadata": {
        "id": "s-M1StxA3CPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decisionTree.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ab4ed3-a0a9-4edd-b0e7-6a180805198d",
        "id": "aOPOs7fzGRX8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.015, criterion='entropy', max_depth=3)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And compute its performance :"
      ],
      "metadata": {
        "id": "tOSCHcFE3FW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decisionTree.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd68ceea-ef48-47a8-eb99-de0ad1f22e4b",
        "id": "b2Mid8piGRX8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4969387755102041"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here, we lose 0.8% of precision with Pruning but it is a technique worth knowing when we want to reduce the complexity of a Decision Tree.**\n",
        "\n",
        "Let's display its associated graph:"
      ],
      "metadata": {
        "id": "GCH5o2yy3I5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "\n",
        "dot_data = tree.export_graphviz(decisionTree, out_file=None,\n",
        "                                feature_names=features.columns.to_list(),\n",
        "                                #class_names=df.species_binary.name,\n",
        "                                class_names=[str(x) for x in labels_unique],\n",
        "                                filled=True, rounded=True,\n",
        "                                special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"wine2\")\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "01m1NfXXGkYi",
        "outputId": "addbaef0-2b2f-4f95-f9c2-fa4181319fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fe68febec90>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1119pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 1118.50 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-429 1114.5,-429 1114.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#d3f9f9\" stroke=\"#000000\" d=\"M632.5,-425C632.5,-425 371.5,-425 371.5,-425 365.5,-425 359.5,-419 359.5,-413 359.5,-413 359.5,-354 359.5,-354 359.5,-348 365.5,-342 371.5,-342 371.5,-342 632.5,-342 632.5,-342 638.5,-342 644.5,-348 644.5,-354 644.5,-354 644.5,-413 644.5,-413 644.5,-419 638.5,-425 632.5,-425\"/>\n<text text-anchor=\"start\" x=\"452.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">alcohol ≤ 10.85</text>\n<text text-anchor=\"start\" x=\"451\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.851</text>\n<text text-anchor=\"start\" x=\"450\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3918</text>\n<text text-anchor=\"start\" x=\"367.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [15, 120, 1156, 1768, 714, 142, 3]</text>\n<text text-anchor=\"start\" x=\"473\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#f5fefe\" stroke=\"#000000\" d=\"M483,-306C483,-306 247,-306 247,-306 241,-306 235,-300 235,-294 235,-294 235,-235 235,-235 235,-229 241,-223 247,-223 247,-223 483,-223 483,-223 489,-223 495,-229 495,-235 495,-235 495,-294 495,-294 495,-300 489,-306 483,-306\"/>\n<text text-anchor=\"start\" x=\"294\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">volatile acidity ≤ 0.267</text>\n<text text-anchor=\"start\" x=\"314\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.635</text>\n<text text-anchor=\"start\" x=\"313\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2459</text>\n<text text-anchor=\"start\" x=\"243\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [8, 89, 1021, 1090, 223, 28, 0]</text>\n<text text-anchor=\"start\" x=\"336\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M454.084,-341.8796C443.3007,-332.513 431.7671,-322.4948 420.6961,-312.8784\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"422.9653,-310.2134 413.1205,-306.2981 418.3749,-315.4982 422.9653,-310.2134\"/>\n<text text-anchor=\"middle\" x=\"414.874\" y=\"-327.5365\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#d9faf9\" stroke=\"#000000\" d=\"M753,-306C753,-306 525,-306 525,-306 519,-306 513,-300 513,-294 513,-294 513,-235 513,-235 513,-229 519,-223 525,-223 525,-223 753,-223 753,-223 759,-223 765,-229 765,-235 765,-235 765,-294 765,-294 765,-300 759,-306 753,-306\"/>\n<text text-anchor=\"start\" x=\"560\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">free sulfur dioxide ≤ 11.5</text>\n<text text-anchor=\"start\" x=\"588\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.821</text>\n<text text-anchor=\"start\" x=\"587\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1459</text>\n<text text-anchor=\"start\" x=\"521\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [7, 31, 135, 678, 491, 114, 3]</text>\n<text text-anchor=\"start\" x=\"610\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M549.916,-341.8796C560.6993,-332.513 572.2329,-322.4948 583.3039,-312.8784\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"585.6251,-315.4982 590.8795,-306.2981 581.0347,-310.2134 585.6251,-315.4982\"/>\n<text text-anchor=\"middle\" x=\"589.126\" y=\"-327.5365\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#bdf6f5\" stroke=\"#000000\" d=\"M232,-179.5C232,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 232,-111.5 232,-111.5 238,-111.5 244,-117.5 244,-123.5 244,-123.5 244,-167.5 244,-167.5 244,-173.5 238,-179.5 232,-179.5\"/>\n<text text-anchor=\"start\" x=\"71\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.603</text>\n<text text-anchor=\"start\" x=\"70\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1312</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 13, 386, 697, 188, 24, 0]</text>\n<text text-anchor=\"start\" x=\"93\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M280.0104,-222.8796C254.2907,-210.2843 226.1648,-196.5107 200.8637,-184.1205\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"202.2001,-180.8778 191.6798,-179.623 199.1214,-187.1645 202.2001,-180.8778\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#bff7c6\" stroke=\"#000000\" d=\"M477.5,-179.5C477.5,-179.5 274.5,-179.5 274.5,-179.5 268.5,-179.5 262.5,-173.5 262.5,-167.5 262.5,-167.5 262.5,-123.5 262.5,-123.5 262.5,-117.5 268.5,-111.5 274.5,-111.5 274.5,-111.5 477.5,-111.5 477.5,-111.5 483.5,-111.5 489.5,-117.5 489.5,-123.5 489.5,-123.5 489.5,-167.5 489.5,-167.5 489.5,-173.5 483.5,-179.5 477.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"325\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.472</text>\n<text text-anchor=\"start\" x=\"324\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1147</text>\n<text text-anchor=\"start\" x=\"270.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 76, 635, 393, 35, 4, 0]</text>\n<text text-anchor=\"start\" x=\"347\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 5</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M368.8473,-222.8796C369.8332,-212.2134 370.8973,-200.7021 371.8957,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"375.3926,-190.0947 372.828,-179.8149 368.4224,-189.4503 375.3926,-190.0947\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#defbfa\" stroke=\"#000000\" d=\"M718.5,-179.5C718.5,-179.5 539.5,-179.5 539.5,-179.5 533.5,-179.5 527.5,-173.5 527.5,-167.5 527.5,-167.5 527.5,-123.5 527.5,-123.5 527.5,-117.5 533.5,-111.5 539.5,-111.5 539.5,-111.5 718.5,-111.5 718.5,-111.5 724.5,-111.5 730.5,-117.5 730.5,-123.5 730.5,-123.5 730.5,-167.5 730.5,-167.5 730.5,-173.5 724.5,-179.5 718.5,-179.5\"/>\n<text text-anchor=\"start\" x=\"578\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.973</text>\n<text text-anchor=\"start\" x=\"585\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 91</text>\n<text text-anchor=\"start\" x=\"535.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 20, 25, 36, 8, 1, 0]</text>\n<text text-anchor=\"start\" x=\"600\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M635.5025,-222.8796C634.6062,-212.2134 633.6388,-200.7021 632.7312,-189.9015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"636.2088,-189.4867 631.8836,-179.8149 629.2334,-190.0729 636.2088,-189.4867\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#dbfafa\" stroke=\"#000000\" d=\"M989,-187C989,-187 761,-187 761,-187 755,-187 749,-181 749,-175 749,-175 749,-116 749,-116 749,-110 755,-104 761,-104 761,-104 989,-104 989,-104 995,-104 1001,-110 1001,-116 1001,-116 1001,-175 1001,-175 1001,-181 995,-187 989,-187\"/>\n<text text-anchor=\"start\" x=\"821.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">alcohol ≤ 12.083</text>\n<text text-anchor=\"start\" x=\"824\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.742</text>\n<text text-anchor=\"start\" x=\"823\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1368</text>\n<text text-anchor=\"start\" x=\"757\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [6, 11, 110, 642, 483, 113, 3]</text>\n<text text-anchor=\"start\" x=\"846\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M721.5413,-222.8796C741.5724,-212.7791 763.1064,-201.9209 783.5232,-191.626\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"785.152,-194.7245 792.5053,-187.0969 782.0003,-188.4742 785.152,-194.7245\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#c5f7f7\" stroke=\"#000000\" d=\"M853.5,-68C853.5,-68 650.5,-68 650.5,-68 644.5,-68 638.5,-62 638.5,-56 638.5,-56 638.5,-12 638.5,-12 638.5,-6 644.5,0 650.5,0 650.5,0 853.5,0 853.5,0 859.5,0 865.5,-6 865.5,-12 865.5,-12 865.5,-56 865.5,-56 865.5,-62 859.5,-68 853.5,-68\"/>\n<text text-anchor=\"start\" x=\"701\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.722</text>\n<text text-anchor=\"start\" x=\"704\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 827</text>\n<text text-anchor=\"start\" x=\"646.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 9, 97, 420, 252, 44, 0]</text>\n<text text-anchor=\"start\" x=\"723\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 6</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M829.1993,-103.9815C818.7566,-94.5151 807.6667,-84.462 797.2472,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"799.5572,-72.3868 789.7976,-68.2637 794.8559,-77.5731 799.5572,-72.3868\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#f9fafe\" stroke=\"#000000\" d=\"M1098.5,-68C1098.5,-68 895.5,-68 895.5,-68 889.5,-68 883.5,-62 883.5,-56 883.5,-56 883.5,-12 883.5,-12 883.5,-6 889.5,0 895.5,0 895.5,0 1098.5,0 1098.5,0 1104.5,0 1110.5,-6 1110.5,-12 1110.5,-12 1110.5,-56 1110.5,-56 1110.5,-62 1104.5,-68 1098.5,-68\"/>\n<text text-anchor=\"start\" x=\"946\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.648</text>\n<text text-anchor=\"start\" x=\"949\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 541</text>\n<text text-anchor=\"start\" x=\"891.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 2, 13, 222, 231, 69, 3]</text>\n<text text-anchor=\"start\" x=\"968\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 7</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M920.4283,-103.9815C930.7861,-94.5151 941.7859,-84.462 952.1206,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"954.4893,-77.5935 959.5097,-68.2637 949.7669,-72.4264 954.4893,-77.5935\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see here that Pruning removed 6 nodes that it had considered irrelevant."
      ],
      "metadata": {
        "id": "Qgn_lmyk3ioP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Weighted Decision Tree**"
      ],
      "metadata": {
        "id": "uhnxR1VzDBrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let’s look at the hyperparameter that I find the most relevant:\n",
        "\n",
        "- **class_weight *(dictionary)*** – during the criterion computation, the algorithm measures the impurity across all classes in the dataset. It gives an equal weight for each class. But by specifying in class_weight a different weight for each of the classes, the statistic will be different which will influence the final result of the algorithm.\n",
        "- **min_weight_fraction_leaf *(float)*** – The minimum weighted fraction of the total sum of weights (of all input samples) required to be at a leaf node.\n",
        "\n",
        "Let’s use **class_weight.** This can be a powerful option to improve the model as the number of wines differs greatly between classes.\n",
        "\n",
        "**Therefore giving a different weight to the classes will allow the criterion to consider the amount of wine in each class.**\n",
        "\n",
        "We index the value of the weights according to the number of wines in each class: `{3:1, 4:2, 5:4, 6:5, 7:3, 8:2, 9:1}`. Class 3 has a weight of 1, class 4 has a weight of 2, etc.\n",
        "\n",
        "Thus, the higher the number of wines, the higher the weight:"
      ],
      "metadata": {
        "id": "n0CKOxow3lb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "decisionTree = tree.DecisionTreeClassifier(criterion=\"entropy\",\n",
        "                                           class_weight={3:1, 4:2, 5:4, 6:5, 7:3, 8:2, 9:1}\n",
        "                                           )"
      ],
      "metadata": {
        "id": "ByGXEz6bFHN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the Tree:"
      ],
      "metadata": {
        "id": "s7DJ3h_63zLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decisionTree.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8791b36-10b0-4138-a4fd-36da3f506af8",
        "id": "myJyR8DMFHOD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight={3: 1, 4: 2, 5: 4, 6: 5, 7: 3, 8: 2, 9: 1},\n",
              "                       criterion='entropy')"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And compute its performance:"
      ],
      "metadata": {
        "id": "NRSzpRiH31qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decisionTree.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296690db-9e11-4f80-f73b-6febee4b3d8d",
        "id": "GSc8nJE0FHOE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6153061224489796"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We reach 61.5% accuracy! That’s 1.5% more than before.\n",
        "\n",
        "**This “small” improvement is actually a significant improvement! Indeed, in Machine Learning, the most complex task is the optimization of the model.**\n",
        "\n",
        "Improving the performance, even by 1%, is already considerable!\n",
        "\n",
        "And you, what score have you reached?\n",
        "\n",
        "**This optimization method based on changing the hyperparameters is called: Hyperparameter Tuning.**\n",
        "\n",
        "But there are many other techniques to improve a Machine Learning model:\n",
        "\n",
        "- [Normalizing our data](https://inside-machinelearning.com/en/normalize-your-data/)\n",
        "- [Cross-Validation](https://inside-machinelearning.com/en/cross-validation-tutorial/)\n",
        "- Data Augmentation\n",
        "- [Ensemble methods](https://inside-machinelearning.com/en/ensemble-methods/)\n",
        "\n",
        "If you want to stay updated feel free to subscribe to our newsletter 😉"
      ],
      "metadata": {
        "id": "8Mw4vZA_34A0"
      }
    }
  ]
}
